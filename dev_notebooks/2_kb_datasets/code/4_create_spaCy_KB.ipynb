{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create spaCy KB object"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The code used in this notebook is based on the 2020 spaCy entity linking tutorial https://github.com/explosion/projects/blob/v3/tutorials/nel_emerson/notebooks/notebook_video.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis_flores/.local/share/virtualenvs/nel-mBUv7xk_/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import datetime as dt\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.kb import KnowledgeBase"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# For GPU compatible machines\n",
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger(name, log_file, level=logging.DEBUG):\n",
    "    \"\"\"\n",
    "    Setup logger\n",
    "    \"\"\"\n",
    "    handler = logging.FileHandler(log_file)        \n",
    "\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "def days_hours_minutes(td):\n",
    "    \"\"\"\n",
    "    Extract hours, minutes and seconds from timestamp\n",
    "    \"\"\"\n",
    "    hours = td.seconds//3600\n",
    "    minutes=(td.seconds//60)%60\n",
    "    seconds=td.seconds\n",
    "    return f'{hours}:{minutes}:{seconds}' "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NB: the KB object requires the description field to be embbeded. The embbeding can be performed with any compatible spaCy pipeline. In the course of this project we tried embbedings with the standard en_core_web_lg pipeline and en_core_web_trf pipeline, as well as with the bespoke transformer Guardian Person NER model pipeline. At the time of development the transformer models could not be used in the later stages of the project due to an incompatibility with the EL model implementation. This was due to the transformer models producing tensor embbedings, rather than vector embbedings. The spaCy 3.4 EL model could not handle tensor objects when we developed this project, even after using the script found in dev_notebooks/trf_tensor_to_vec.py to add a method to flatten spaCy tensors back to vectors. As such, we had to revert to using the standard en_core_web_lg model for KB embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load spaCy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load spaCy en_web_core_lg pipeline\n",
    "model='lg'\n",
    "nlp = spacy.load(f'en_core_web_lg')\n",
    "\n",
    "text = \"Example text to embbed and assess vector dimensions\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Find nlp model embedding dimensions\n",
    "embedding_dims=len(doc.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(embedding_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The first step to perform Entity Linking, is to set up a knowledge base that contains the unique identifiers of the entities we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='full'# OR'open_sanctions'# OR 'lilsis'\n",
    "kb_iteration='_2022_11_07'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis_flores/.local/share/virtualenvs/nel-mBUv7xk_/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: DtypeWarning: Columns (2,7,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Import kb dataset\n",
    "data=pd.read_csv(f'../assets/kb_entities_{dataset}{kb_iteration}.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428519, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the three required KB fields\n",
    "kb_data=data[['id','name','desc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acf-00040861bc3f593000830d987d09967ef3503ef1</td>\n",
       "      <td>Kolyvanov Egor</td>\n",
       "      <td>Kolyvanov Egor is a Russian propagandist: host...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acf-0011c68a768924609dc5da5707ac7fa4c4d645a2</td>\n",
       "      <td>Shipov Sergei Yurievich</td>\n",
       "      <td>Shipov Sergei Yurievich is a Russian chess pla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id                     name  \\\n",
       "0  acf-00040861bc3f593000830d987d09967ef3503ef1           Kolyvanov Egor   \n",
       "1  acf-0011c68a768924609dc5da5707ac7fa4c4d645a2  Shipov Sergei Yurievich   \n",
       "\n",
       "                                                desc  \n",
       "0  Kolyvanov Egor is a Russian propagandist: host...  \n",
       "1  Shipov Sergei Yurievich is a Russian chess pla...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raise exception if duplicated IDs are found in the dataset\n",
    "if (kb_data['id'].duplicated().any()) | (kb_data['id'].nunique()!=kb_data.shape[0]):\n",
    "    raise Exception('There might be duplicate entitiy IDs in the KB file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe into dictionaries mapping IDs to aliases and descriptions\n",
    "names_dict = dict()\n",
    "desc_dict = dict()\n",
    "\n",
    "for row in kb_data.iterrows():\n",
    "    qid = str(row[1][0])\n",
    "    name = str(row[1][1])\n",
    "    desc = str(row[1][2])\n",
    "    names_dict[qid] = name\n",
    "    desc_dict[qid] = desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Map many-to-one IDs to aliases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliases_data=kb_data[kb_data['name'].duplicated(keep=False)].sort_values(['name'])\n",
    "aliases_data['id']=aliases_data['id'].astype(str)\n",
    "alias_dict={}\n",
    "for alias in aliases_data['name'].unique():\n",
    "    alias_dict[alias]=list(aliases_data.loc[aliases_data['name']==alias, 'id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['280783',\n",
       " '211703',\n",
       " '53881',\n",
       " '200407',\n",
       " '377020',\n",
       " '204251',\n",
       " '184041',\n",
       " '77215',\n",
       " 'Q3018800',\n",
       " '221595',\n",
       " 'Q53960880',\n",
       " 'Q5239878',\n",
       " '200405']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entity IDs sharing alias David Smith\n",
    "alias_dict['David Smith']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>name</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acf-00040861bc3f593000830d987d09967ef3503ef1</td>\n",
       "      <td>Kolyvanov Egor</td>\n",
       "      <td>Kolyvanov Egor is a Russian propagandist: host...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acf-0011c68a768924609dc5da5707ac7fa4c4d645a2</td>\n",
       "      <td>Shipov Sergei Yurievich</td>\n",
       "      <td>Shipov Sergei Yurievich is a Russian chess pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acf-001e7e4c0363f08f1e784c230457960b84a6416f</td>\n",
       "      <td>Egorov Ivan Mikhailovich</td>\n",
       "      <td>Egorov Ivan Mikhailovich is a Deputy of the St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acf-002c208139012c8d93b6298358188d7cadafe648</td>\n",
       "      <td>Goreslavsky Alexey Sergeyevich</td>\n",
       "      <td>Goreslavsky Alexey Sergeyevich is a Russian jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acf-002cc8fdf8fe41185091a7cb6c598663e7a22eb5</td>\n",
       "      <td>Samoilova Natalya Vladimirovna</td>\n",
       "      <td>Samoilova Natalya Vladimirovna is a Russian si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428514</th>\n",
       "      <td>413772</td>\n",
       "      <td>Cory Bernardi</td>\n",
       "      <td>Cory Bernardi is a Australian politician and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428515</th>\n",
       "      <td>Q47668202</td>\n",
       "      <td>Jalbasürengiin Batzandan</td>\n",
       "      <td>Jalbasürengiin Batzandan is a Mongolian politi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428516</th>\n",
       "      <td>13488</td>\n",
       "      <td>Patrick Murphy</td>\n",
       "      <td>Patrick Murphy is a former US Representative f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428517</th>\n",
       "      <td>Q28033808</td>\n",
       "      <td>Sharif Street</td>\n",
       "      <td>Sharif Street is a American politician from Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428518</th>\n",
       "      <td>407938</td>\n",
       "      <td>Wendy Carrillo</td>\n",
       "      <td>Wendy Carrillo is a Assemblymember representin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428519 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 qid  \\\n",
       "0       acf-00040861bc3f593000830d987d09967ef3503ef1   \n",
       "1       acf-0011c68a768924609dc5da5707ac7fa4c4d645a2   \n",
       "2       acf-001e7e4c0363f08f1e784c230457960b84a6416f   \n",
       "3       acf-002c208139012c8d93b6298358188d7cadafe648   \n",
       "4       acf-002cc8fdf8fe41185091a7cb6c598663e7a22eb5   \n",
       "...                                              ...   \n",
       "428514                                        413772   \n",
       "428515                                     Q47668202   \n",
       "428516                                         13488   \n",
       "428517                                     Q28033808   \n",
       "428518                                        407938   \n",
       "\n",
       "                                  name  \\\n",
       "0                       Kolyvanov Egor   \n",
       "1              Shipov Sergei Yurievich   \n",
       "2             Egorov Ivan Mikhailovich   \n",
       "3       Goreslavsky Alexey Sergeyevich   \n",
       "4       Samoilova Natalya Vladimirovna   \n",
       "...                                ...   \n",
       "428514                   Cory Bernardi   \n",
       "428515        Jalbasürengiin Batzandan   \n",
       "428516                  Patrick Murphy   \n",
       "428517                   Sharif Street   \n",
       "428518                  Wendy Carrillo   \n",
       "\n",
       "                                                     desc  \n",
       "0       Kolyvanov Egor is a Russian propagandist: host...  \n",
       "1       Shipov Sergei Yurievich is a Russian chess pla...  \n",
       "2       Egorov Ivan Mikhailovich is a Deputy of the St...  \n",
       "3       Goreslavsky Alexey Sergeyevich is a Russian jo...  \n",
       "4       Samoilova Natalya Vladimirovna is a Russian si...  \n",
       "...                                                   ...  \n",
       "428514  Cory Bernardi is a Australian politician and r...  \n",
       "428515  Jalbasürengiin Batzandan is a Mongolian politi...  \n",
       "428516  Patrick Murphy is a former US Representative f...  \n",
       "428517  Sharif Street is a American politician from Pe...  \n",
       "428518  Wendy Carrillo is a Assemblymember representin...  \n",
       "\n",
       "[428519 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export kb data in right format for tutorialkb_data\n",
    "kb_data.rename(columns={'id':'qid','context':'desc'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embbed and export kb descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedings_path='../assets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create file handler which logs even debug messages\n",
    "cycle_logger=setup_logger(f'{embedings_path}/{model}_model_cycle_logger',f'../assets/{model}_model_cycle_execution_times.log')\n",
    "# create file handler which logs failed embeddings\n",
    "failed_embeddings_logger=setup_logger(f'{embedings_path}/{model}_model_failed_embeddings',f'../assets/{model}_model_embeddings.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Embbed and export kb descriptions\n",
    "cycle_logger.debug('------')\n",
    "cycle_logger.debug('Embeddings run start')\n",
    "cycle_logger.debug('------')\n",
    "\n",
    "start_runtime=dt.datetime.now()\n",
    "num_embeddings=0\n",
    "runtime_log=start_runtime.strftime('%Y_%m_%d_%H:%M:%S')\n",
    "log_str=f'Number of embeddings:{num_embeddings}, Runtime:{runtime_log}'\n",
    "cycle_logger.debug(log_str)\n",
    "descriptions_emb = dict()\n",
    "export_cycle_interval=10000\n",
    "filename=f'{embedings_path}/{model}_model_embeddings_dict_pkl'\n",
    "for qid, desc in desc_dict.items():\n",
    "    try:\n",
    "        desc_doc = nlp(desc)\n",
    "        desc_emb = desc_doc.vector\n",
    "        descriptions_emb[qid]=desc_emb\n",
    "    except:\n",
    "        failed_embeddings_logger.debug(f'{qid}')\n",
    "        continue\n",
    "    num_embeddings+=1    \n",
    "    if (num_embeddings%export_cycle_interval==0) | (num_embeddings==len(desc_dict)):\n",
    "        \n",
    "        # Export embeddings\n",
    "        with open(f'{filename}{kb_iteration}.pickle', 'wb') as handle:\n",
    "            pickle.dump(descriptions_emb, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        # Logging\n",
    "        current_runtime = dt.datetime.now()\n",
    "        runtime_log = current_runtime.strftime('%Y_%m_%d_%H:%M:%S')\n",
    "        time_delta = current_runtime - start_runtime \n",
    "        time_delta = days_hours_minutes(time_delta)\n",
    "        log_str=f'Number of embeddings:{num_embeddings}, Runtime:{runtime_log}, Timedelta:{time_delta}'\n",
    "        cycle_logger.debug(log_str)\n",
    "        \n",
    "cycle_logger.debug('------')\n",
    "cycle_logger.debug('Embeddings run end')\n",
    "cycle_logger.debug('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = KnowledgeBase(vocab=nlp.vocab, entity_vector_length=embedding_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open embeddings export file \n",
    "filename=f'{embedings_path}/{model}_model_embeddings_dict_pkl'\n",
    "with open(f'{filename}{kb_iteration}.pickle', 'rb') as f:\n",
    "    description_emb = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428519"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(description_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(description_emb)==data.shape[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NB: The vector attribute of a document is the average of its token vectors' nlp model embeddings. Another parameter that needs to be passed to the KB is a frequency. The frequency should be estimated as the raw count of how many times a certain entity appears in an annotated corpus, but in the current iteration we used an arbitrary value to assign equal number of counts across entities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add entities, embbeded descriptions and word counts to KB\n",
    "arbitrary_freq_value=342\n",
    "for qid, vector in description_emb.items():\n",
    "    kb.add_entity(entity=qid, entity_vector=vector, freq=arbitrary_freq_value)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NB: The spaCy KB object also requires a mapping from entities to an alias. An additional parameter required for this mapping is the prior probability of each entity ID mapped to the alias. This value is used by the EL model to weight candidate predictions (candidates with higher priors will have their predictions scores weighted up). To avoid ending up with a redundant model based entirely on prior probabilities we assigned an arbitrary probability value accross all IDs, even when there was a single candidate per alias. This was done to avoid downstream issues related to our bespoke candidate generation function (which, unlike the standard candidate generation function implemented in the original EL tutorial, generated up to 10Ks candidates). Since the priors belonging to an alias must sum to 1 the value chosen was non-zero, but small enough to account for 100K candidates. The option to disregard the prior probabilty in predictions was also defined in the config file used to train the model.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arbitrary_prob=0.000001 \n",
    "for qid, name in names_dict.items():\n",
    "    if name not in alias_dict.keys():\n",
    "        kb.add_alias(alias=str(name), entities=[str(qid)], probabilities=[arbitrary_prob])   # 100% prior probability P(entity|alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alias_ in alias_dict.keys():\n",
    "    qids=alias_dict[alias_]\n",
    "    # change to 0 still not implemented in KB objects\n",
    "    #probs = [round(1/len(qids),2)-.01 for qid in qids]\n",
    "    probs=[arbitrary_prob for qid in qids]\n",
    "    kb.add_alias(alias=alias_, entities=qids, probabilities=probs)  # sum([probs]) should be <= 1 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sense checks for aliases/entity mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidates for Joe Biden: ['13047']\n"
     ]
    }
   ],
   "source": [
    "candidate_1='Joe Biden'\n",
    "print(f\"Candidates for {candidate_1}: {[c.entity_ for c in kb.get_alias_candidates(candidate_1)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidates for Adam Smith: ['129552', '379819', '269916', '256328', '13596']\n"
     ]
    }
   ],
   "source": [
    "candidate_2='Adam Smith'\n",
    "print(f\"Candidates for {candidate_2}: {[c.entity_ for c in kb.get_alias_candidates(candidate_2)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidates for David Smith: ['280783', '211703', '53881', '200407', '377020', '204251', '184041', '77215', 'Q3018800', '221595', 'Q53960880', 'Q5239878', '200405']\n"
     ]
    }
   ],
   "source": [
    "candidate_3='David Smith'\n",
    "print(f\"Candidates for {candidate_3}: {[c.entity_ for c in kb.get_alias_candidates(candidate_3)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save KB object to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save KB object to disk\n",
    "output_dir=\"../assets/\"\n",
    "kb.to_disk(f'{output_dir}kb_{model}_model{kb_iteration}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
