{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare and run EL training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis_flores/.local/share/virtualenvs/nel-mBUv7xk_/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import typer\n",
    "import json\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "from spacy.tokens import DocBin, Span\n",
    "from spacy.kb import KnowledgeBase, Candidate\n",
    "import custom_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_no_candidates(row, no_candidate_sub_str=['NEL','NER']):\n",
    "    \"\"\"\n",
    "    Find annotations without candidates\n",
    "    \"\"\"\n",
    "    return any(sub_str in ' '.join(row['accept']) for sub_str in no_candidate_sub_str)\n",
    "\n",
    "def find_best_candidate(row,best_candidate=0):\n",
    "    \"\"\"\n",
    "    In multiple choice annotations select the candadite with the longest description\n",
    "    \"\"\"\n",
    "    best_candidate_d={}\n",
    "    for option_id in row['accept']:\n",
    "        for candidate in list(filter(lambda x: option_id == x['id'], row['options'])):\n",
    "            candidate_len=len(candidate['html'].split('a>:')[1])\n",
    "            best_candidate_d[option_id]=candidate_len\n",
    "    return [max(best_candidate_d, key=best_candidate_d.get)]\n",
    "\n",
    "def make_doc(example):\n",
    "    \"\"\"\n",
    "    Construct spaCy document object from dataset \n",
    "    \"\"\"\n",
    "    sentence = example[\"text\"]\n",
    "    if example[\"answer\"] == \"accept\":\n",
    "        QID = example[\"accept\"]#[0]\n",
    "        doc = nlp.make_doc(sentence)\n",
    "        gold_ids.append(QID)\n",
    "        entity = doc.char_span(\n",
    "            example[\"start_char\"],\n",
    "            example[\"end_char\"],\n",
    "            label=example[\"label\"],\n",
    "            kb_id=QID,\n",
    "        )\n",
    "        doc.ents = [entity]\n",
    "        for i, t in enumerate(doc):\n",
    "            doc[i].is_sent_start = i == 0\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_seed=42"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# For GPU compatible machines\n",
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load annotation session data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_session_1 = pd.read_json('../../3_prodigy_annotations/assets/prodigy_sessions/el_session_1.jsonl',lines=True)\n",
    "data_session_2 = pd.read_json('../../3_prodigy_annotations/assets/prodigy_sessions/el_session_2.jsonl',lines=True)\n",
    "data_session_3 = pd.read_json('../../3_prodigy_annotations/assets/prodigy_sessions/el_session_3.jsonl',lines=True)\n",
    "df = data_session_1.append(data_session_2).append(data_session_3).reset_index(drop=True)\n",
    "del(data_session_1)\n",
    "del(data_session_2)\n",
    "del(data_session_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4978, 17)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove instances without viable candidates \n",
    "df = df[~df.apply(find_no_candidates,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2880, 17)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis_flores/.local/share/virtualenvs/nel-mBUv7xk_/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Remove instances wrongly accepted without any selected options\n",
    "df['accept_len'] = df['accept'].apply(lambda x: len(''.join(x))).sort_values()\n",
    "df = df[df['accept_len']!=0]\n",
    "df.drop('accept_len',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2876, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In cases with multiple annotated candidates, select candidate with the longest description \n",
    "df['accept']=df.apply(find_best_candidate,1)\n",
    "# Extract accepted id from list \n",
    "df['accept']=df['accept'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract info from spaCy span dictionary\n",
    "df.loc[:,'ents'] = df.loc[:,'spans'].apply(lambda x: x[0]['text'])\n",
    "df['start_char'] = df['spans'].apply(lambda x: x[0][\"start\"])\n",
    "df['end_char'] = df['spans'].apply(lambda x: x[0][\"end\"])\n",
    "df['label'] = df['spans'].apply(lambda x: x[0][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1449"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ents'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Make train and dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "sampling_col = '_input_hash'\n",
    "index_train, index_test = train_test_split(df[sampling_col].unique(), test_size=0.1, random_state=rng_seed)\n",
    "df_train = df[df[sampling_col].isin(index_train)]\n",
    "df_test = df[df[sampling_col].isin(index_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 21), (62, 21))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further wrangling\n",
    "df_train=df_train[['ents','text','accept','start_char','end_char','label','answer']]\n",
    "df_test=df_test[['ents','text','accept','start_char','end_char','label','answer']]\n",
    "# Order train dataset randomly\n",
    "df_train=df_train.sample(frac=1, random_state=rng_seed)\n",
    "df_train=df_train.drop_duplicates()\n",
    "df_test=df_test.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ents</th>\n",
       "      <th>text</th>\n",
       "      <th>accept</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "      <th>label</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>Muhyiddin</td>\n",
       "      <td>Anwar was due to succeed then-prime minister M...</td>\n",
       "      <td>Q1060949</td>\n",
       "      <td>151</td>\n",
       "      <td>160</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>Vitter</td>\n",
       "      <td>Fleming and fellow congressman Charles Boustan...</td>\n",
       "      <td>13645</td>\n",
       "      <td>95</td>\n",
       "      <td>101</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>accept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ents                                               text    accept  \\\n",
       "3113  Muhyiddin  Anwar was due to succeed then-prime minister M...  Q1060949   \n",
       "3262     Vitter  Fleming and fellow congressman Charles Boustan...     13645   \n",
       "\n",
       "      start_char  end_char   label  answer  \n",
       "3113         151       160  PERSON  accept  \n",
       "3262          95       101  PERSON  accept  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ents</th>\n",
       "      <th>text</th>\n",
       "      <th>accept</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "      <th>label</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corbyn</td>\n",
       "      <td>The Welsh Labour leader, Carwyn Jones has reje...</td>\n",
       "      <td>Q291169</td>\n",
       "      <td>73</td>\n",
       "      <td>79</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Corbyn</td>\n",
       "      <td>The Welsh Labour leader, Carwyn Jones has reje...</td>\n",
       "      <td>Q291169</td>\n",
       "      <td>254</td>\n",
       "      <td>260</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>accept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ents                                               text   accept  \\\n",
       "4  Corbyn  The Welsh Labour leader, Carwyn Jones has reje...  Q291169   \n",
       "5  Corbyn  The Welsh Labour leader, Carwyn Jones has reje...  Q291169   \n",
       "\n",
       "   start_char  end_char   label  answer  \n",
       "4          73        79  PERSON  accept  \n",
       "5         254       260  PERSON  accept  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export train and test sets\n",
    "df_train_dir='../assets/df_train.csv'\n",
    "df_test_dir='../assets/df_test.csv'\n",
    "df_train.to_csv(df_train_dir)\n",
    "df_test.to_csv(df_test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `.spacy` corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "nlp_model = 'en_core_web_lg'\n",
    "nlp = spacy.load(nlp_model, exclude=\"parser, tagger\")\n",
    "train_corpus = '../assets/el_train.spacy'\n",
    "test_corpus = '../assets/el_test.spacy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Generate spaCy Docs to train/test model\n",
    "gold_ids = []\n",
    "\n",
    "train_docs = df_train.apply(make_doc, axis=1)\n",
    "test_docs = df_test.apply(make_doc, axis=1)\n",
    "train_docbin = DocBin()\n",
    "test_docbin = DocBin()\n",
    "\n",
    "for doc in train_docs:\n",
    "    train_docbin.add(doc)\n",
    "for doc in test_docs:\n",
    "    test_docbin.add(doc)\n",
    "\n",
    "train_docbin.to_disk(train_corpus)\n",
    "test_docbin.to_disk(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NB: in this project we used a bespoke candidate generation function, provided as an argument to the spaCy train script. The candidate generation can be found in custom_functions.py. The default spaCy 3.4 candidate generation mapped all possible candidates for any given alias during KB creation and then simply fecthed the candidates  mapped to whichever alias exactly matched the text mention. This definition was too rigid for our purposes, so we created a looser candidate generation logic based on string fuzzy matching thresholds. This had disadvantages in terms of increased computational overhead, but mainly the fact that the number of candidates could reach up to tens of thousands for common single name mentions (e.g. Johnson, Smith...), with possible implications in the number of negative examples used during training.   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "!python -m spacy train configs/nel.cfg --output training --paths.train ../assets/el_train.spacy --paths.dev ../assets/el_test.spacy \\\n",
    "    --paths.kb ../../2_kb_datasets/assets/kb_lg_model_2022_11_07 --paths.base_nlp en_core_web_lg -c custom_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Package model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NB: After training the EL model must be packaged to be able to access and run the custom_functions.py script.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_model='en_core_web_lg'\n",
    "nlp=spacy.load(el_model)\n",
    "nlp.add_pipe('entity_linker')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!python -m spacy package --force training/model-best/ training/ --code custom_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Validate model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NB: Model validation was a major issue in this project. The majority of annotations were performed on mentions containing only one possible candidate, or duplicated KB candidates (different identity IDs and usually similar descriptions for the same real-world person). However these cases are not suitable to validate the model, given that correct links can be attributed to the candidate generation step directly (i.e. the model isn't actually required). Many more cases of candidate ambiguity are required to compreensively validate an EL model, so future datasets should take this fact into account. A related issue was that there were not enought single-name aliases available in the dataset to train the model, and subsequently validate it. An important learning and recommendation for future iterations is that model validation is taken into account from the start of development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis_flores/.local/share/virtualenvs/nel-mBUv7xk_/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: DtypeWarning: Columns (2,7,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Load EL model\n",
    "el_model='training/en_pipeline-0.0.0/en_pipeline/en_pipeline-0.0.0'\n",
    "nlp=spacy.load(el_model)\n",
    "\n",
    "# Load KB\n",
    "kb_loc='../../2_kb_datasets/assets/kb_lg_model_2022_11_07/'\n",
    "\n",
    "sentence='John Michael was born in Paris in 1992'\n",
    "doc=nlp(sentence)\n",
    "embedding_len=len(doc.vector)\n",
    "\n",
    "kb = KnowledgeBase(vocab=nlp.vocab, entity_vector_length=embedding_len)\n",
    "kb.from_disk(kb_loc)\n",
    "\n",
    "# Load KB dataset\n",
    "dataset='full'# OR'open_sanctions'# OR 'lilsis'\n",
    "kb_iteration='_2022_11_07'\n",
    "kb_data=pd.read_csv(f'../../2_kb_datasets/assets/kb_entities_{dataset}{kb_iteration}.csv',index_col=0)\n",
    "\n",
    "# Count number of duplicates per KB alias\n",
    "kb_data['id']=kb_data['id'].astype(str)\n",
    "alias_duplication = kb_data['name'].value_counts().reset_index().rename(columns={'index':'name', 'name':'duplicate_counts'})\n",
    "kb_data=kb_data.merge(alias_duplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run predictions and extract results for person mentions in test dataset\n",
    "df_lst=[]\n",
    "texts=df_test['text'].unique()\n",
    "i = 0\n",
    "for text in texts:\n",
    "    row_lst=[]\n",
    "    doc=nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'PERSON':\n",
    "            row_lst.append([text, ent.text, ent.kb_id_])\n",
    "    df_lst.extend(row_lst)\n",
    "    i +=1\n",
    "    if i% 100 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect predictions \n",
    "df_predictions=pd.DataFrame(df_lst,columns=['text', 'ents', 'pred_qid'])\n",
    "df_predictions=df_predictions.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ents</th>\n",
       "      <th>pred_qid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Welsh Labour leader, Carwyn Jones has reje...</td>\n",
       "      <td>Carwyn Jones</td>\n",
       "      <td>Q111840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Welsh Labour leader, Carwyn Jones has reje...</td>\n",
       "      <td>Corbyn</td>\n",
       "      <td>Q291169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“Liz Truss will be travelling the country wear...</td>\n",
       "      <td>Liz Truss</td>\n",
       "      <td>Q272201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“Liz Truss will be travelling the country wear...</td>\n",
       "      <td>Rishi</td>\n",
       "      <td>Q44274451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The British chancellor, George Osborne, said T...</td>\n",
       "      <td>George Osborne</td>\n",
       "      <td>Q332493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>The Jouyets married in 2006, seven years after...</td>\n",
       "      <td>Brigitte</td>\n",
       "      <td>Q916162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>The Jouyets married in 2006, seven years after...</td>\n",
       "      <td>Anne-Claire Taittinger</td>\n",
       "      <td>311246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>The Jouyets married in 2006, seven years after...</td>\n",
       "      <td>Norman</td>\n",
       "      <td>Q332546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Defence minister Mark Lancaster wrote to McDon...</td>\n",
       "      <td>Mark Lancaster</td>\n",
       "      <td>Q750161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>The then US ambassador to the UN, Nikki Haley,...</td>\n",
       "      <td>Nikki Haley</td>\n",
       "      <td>Q11668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    The Welsh Labour leader, Carwyn Jones has reje...   \n",
       "1    The Welsh Labour leader, Carwyn Jones has reje...   \n",
       "2    “Liz Truss will be travelling the country wear...   \n",
       "3    “Liz Truss will be travelling the country wear...   \n",
       "4    The British chancellor, George Osborne, said T...   \n",
       "..                                                 ...   \n",
       "104  The Jouyets married in 2006, seven years after...   \n",
       "105  The Jouyets married in 2006, seven years after...   \n",
       "106  The Jouyets married in 2006, seven years after...   \n",
       "107  Defence minister Mark Lancaster wrote to McDon...   \n",
       "108  The then US ambassador to the UN, Nikki Haley,...   \n",
       "\n",
       "                       ents   pred_qid  \n",
       "0              Carwyn Jones    Q111840  \n",
       "1                    Corbyn    Q291169  \n",
       "2                 Liz Truss    Q272201  \n",
       "3                     Rishi  Q44274451  \n",
       "4            George Osborne    Q332493  \n",
       "..                      ...        ...  \n",
       "104                Brigitte    Q916162  \n",
       "105  Anne-Claire Taittinger     311246  \n",
       "106                  Norman    Q332546  \n",
       "107          Mark Lancaster    Q750161  \n",
       "108             Nikki Haley     Q11668  \n",
       "\n",
       "[104 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve annotator info to predictions  \n",
    "df_predictions=df_test.merge(df_predictions, on=['text','ents'], how='outer').drop_duplicates().sort_values('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve KB information for prediction ids\n",
    "df_predictions=df_predictions.merge(kb_data[['id','name','desc','kb_origin', 'duplicate_counts']], left_on=['pred_qid'], right_on=['id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "df_predictions=df_predictions[['text','ents','accept','pred_qid', 'id', 'name', 'desc', 'duplicate_counts', 'kb_origin', 'start_char', 'end_char']].rename(columns={'ents':'mention','id':'kb_id', 'name':'kb_name'})                                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect predictions\n",
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect instances where top choice matches prediction\n",
    "df_predictions[df_predictions['accept']==df_predictions['pred_qid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect instances where mention matches kb aliases\n",
    "df_predictions[df_predictions['mention']==df_predictions['kb_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect instances where linking is different from top choice, but still matches the alias\n",
    "df_predictions[(df_predictions['accept']!=df_predictions['pred_qid'])&(df_predictions['mention']==df_predictions['kb_name'])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
