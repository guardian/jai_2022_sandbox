{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "189a8a35-ac7f-4427-a329-6bb879170a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/jai_venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "689804e3-27de-47bc-a2fc-a143ca7f5226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53a7507b-d60b-46d3-9944-a09f2ba926b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8775b99c-b1b6-4a1e-b55b-9bb6847f38ac",
   "metadata": {},
   "source": [
    "import boto3\n",
    "\n",
    "REGION = \"eu-west-1\"\n",
    "SESSION = boto3.Session(region_name=REGION)\n",
    "\n",
    "def list_models_on_s3(bucket, path, session, endpoint_url=None):\n",
    "    s3 = session.resource(\"s3\", endpoint_url=endpoint_url)\n",
    "    my_bucket = s3.Bucket(bucket)\n",
    "    bucket_contents = []\n",
    "    for my_bucket_object in my_bucket.objects.filter(Prefix=path):\n",
    "        if not my_bucket_object.key.endswith(\"/\"):\n",
    "            bucket_contents.append(my_bucket_object.key)\n",
    "    return bucket_contents\n",
    "\n",
    "\n",
    "def load_files_from_s3(bucket, session, file_list, destination, endpoint_url=None):\n",
    "    s3 = session.resource(\"s3\", endpoint_url=endpoint_url)\n",
    "    my_bucket = s3.Bucket(bucket)\n",
    "    for file in file_list:\n",
    "        if '2022' in file:\n",
    "            my_bucket.download_file(file, destination + file.split(\"/\")[-1])\n",
    "    return destination\n",
    "\n",
    "bucket='jai-datasets'\n",
    "path='GU_sample_data'\n",
    "session=SESSION\n",
    "list_models_on_s3(bucket,path,session)\n",
    "\n",
    "bucket='jai-datasets'\n",
    "path='GU_sample_data'\n",
    "session=SESSION\n",
    "file_list=list_models_on_s3(bucket,path,session)\n",
    "destination = '/home/ubuntu/JAI/data/'\n",
    "load_files_from_s3(bucket, session, file_list, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0a6ece6-0a6e-42b5-afa1-7dc4df5d822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce1380b-8025-431b-96d3-0403b2072623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(doc_index,doc,ent_types):\n",
    "    \"\"\"\n",
    "    Extract the entity data (text, label, start, end, start_char, end_char) \n",
    "    from a Spacy Doc and format into JSON.\n",
    "    Filter output to only include `ent_types`.\n",
    "    :returns dict\n",
    "    \"\"\"\n",
    "    ents = [\n",
    "        {\n",
    "            \"text\": ent.text,\n",
    "            \"label\": ent.label_,\n",
    "            \"start\": ent.start,\n",
    "            \"end\": ent.end,\n",
    "            \"start_char\": ent.start_char,\n",
    "            \"end_char\": ent.end_char,\n",
    "        }\n",
    "        for ent in doc.ents\n",
    "        if ent.label_ in ent_types\n",
    "    ]\n",
    "    return {\"doc_index\":doc_index,\n",
    "            #\"text\": doc.text, \n",
    "            \"ents\": ents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ef7d19-f5e6-4eaa-b8fb-1bfedac0836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_TRF_MODEL=\"en_core_web_trf\"\n",
    "nlp = spacy.load(NER_TRF_MODEL)\n",
    "ent_types = nlp.pipe_labels[\"ner\"]\n",
    "unwanted_ent_types=['CARDINAL','LANGUAGE','ORDINAL','PERCENT','QUANTITY','TIME']\n",
    "ent_types = [ent for ent in ent_types if ent not in unwanted_ent_types]\n",
    "csv_file_list=glob.glob('/home/ubuntu/JAI/data/*.csv')\n",
    "csv_file_list.sort()\n",
    "#start on most recent year\n",
    "csv_file_list.reverse()\n",
    "\n",
    "for csv_file in csv_file_list[1:2]:\n",
    "    csv_file_name=''.join(csv_file.split('/')[-1].split('.')[-2])\n",
    "    export_csv_file=f'/home/ubuntu/JAI/data/extracted_named_entities_output/{csv_file_name}_ner.csv.gz'\n",
    "    if glob.glob(export_csv_file):\n",
    "        # Stop entity extraction for files already processed\n",
    "        continue\n",
    "    data=pd.read_csv(csv_file)\n",
    "    data=data.iloc[:1000]\n",
    "    data['body_text']=data['body_text'].astype('str')\n",
    "    # Ensure incremental ordered index to reference back to articles in the dataset\n",
    "    data=data.reset_index(drop=True).sort_index()\n",
    "    data=data.to_dict('index')\n",
    "    gu_article_list=[data[key]['body_text'] for key in data.keys()]\n",
    "    response_body = []\n",
    "    exceptions=[]\n",
    "    \n",
    "    ## slicing gu_article_list ##\n",
    "    \n",
    "    for doc_index,doc in enumerate(nlp.pipe(gu_article_list[:100], batch_size=20)):\n",
    "        response_body.append(get_data(doc_index,doc, ent_types))\n",
    "    d={}\n",
    "    i=-1\n",
    "    for response in response_body:\n",
    "        for ent_ind,ent in enumerate(response['ents']):\n",
    "            i+=1\n",
    "            ent['doc_index']=response['doc_index']\n",
    "            d[i]=ent\n",
    "    df=pd.DataFrame.from_dict(d,orient='index')\n",
    "    df.to_csv(export_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0d8323d-c65e-4b87-b1fb-eceb9525928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data/extracted_named_entities_output/sampled_GU_content_2017_ner.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c40a1f27-bfec-47b7-a528-10b175ad77d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "      <th>doc_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>DATE</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>DATE</td>\n",
       "      <td>96</td>\n",
       "      <td>97</td>\n",
       "      <td>441</td>\n",
       "      <td>443</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>DATE</td>\n",
       "      <td>259</td>\n",
       "      <td>260</td>\n",
       "      <td>1271</td>\n",
       "      <td>1273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>her early 60s</td>\n",
       "      <td>DATE</td>\n",
       "      <td>270</td>\n",
       "      <td>273</td>\n",
       "      <td>1315</td>\n",
       "      <td>1328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>early twenties</td>\n",
       "      <td>DATE</td>\n",
       "      <td>385</td>\n",
       "      <td>387</td>\n",
       "      <td>1855</td>\n",
       "      <td>1869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4544</th>\n",
       "      <td>4544</td>\n",
       "      <td>Guardian</td>\n",
       "      <td>ORG</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>337</td>\n",
       "      <td>345</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>4545</td>\n",
       "      <td>Guardian</td>\n",
       "      <td>ORG</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>470</td>\n",
       "      <td>478</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4546</th>\n",
       "      <td>4546</td>\n",
       "      <td>GuardianWitness</td>\n",
       "      <td>WORK_OF_ART</td>\n",
       "      <td>104</td>\n",
       "      <td>105</td>\n",
       "      <td>499</td>\n",
       "      <td>514</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4547</th>\n",
       "      <td>4547</td>\n",
       "      <td>GuardianWitness</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "      <td>608</td>\n",
       "      <td>623</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4548</th>\n",
       "      <td>4548</td>\n",
       "      <td>Guardian</td>\n",
       "      <td>ORG</td>\n",
       "      <td>136</td>\n",
       "      <td>137</td>\n",
       "      <td>663</td>\n",
       "      <td>671</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4549 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0             text        label  start  end  start_char  \\\n",
       "0              0               24         DATE     40   41         170   \n",
       "1              1               64         DATE     96   97         441   \n",
       "2              2               30         DATE    259  260        1271   \n",
       "3              3    her early 60s         DATE    270  273        1315   \n",
       "4              4   early twenties         DATE    385  387        1855   \n",
       "...          ...              ...          ...    ...  ...         ...   \n",
       "4544        4544         Guardian          ORG     69   70         337   \n",
       "4545        4545         Guardian          ORG     98   99         470   \n",
       "4546        4546  GuardianWitness  WORK_OF_ART    104  105         499   \n",
       "4547        4547  GuardianWitness      PRODUCT    126  127         608   \n",
       "4548        4548         Guardian          ORG    136  137         663   \n",
       "\n",
       "      end_char  doc_index  \n",
       "0          172          0  \n",
       "1          443          0  \n",
       "2         1273          0  \n",
       "3         1328          0  \n",
       "4         1869          0  \n",
       "...        ...        ...  \n",
       "4544       345         99  \n",
       "4545       478         99  \n",
       "4546       514         99  \n",
       "4547       623         99  \n",
       "4548       671         99  \n",
       "\n",
       "[4549 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5168845d-5c41-42be-a93b-4adf3744ab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting NER extraction\n",
      "INFO:root:Loading Spacy model\n",
      "INFO:root:Starting iteration through csv files\n",
      "INFO:root:------------------------\n",
      "INFO:root:Reading /home/ubuntu/JAI/data/sampled_GU_content_2022.csv data\n",
      "INFO:root:Extracting named entities from /home/ubuntu/JAI/data/sampled_GU_content_2022.csv article 0\n",
      "INFO:root:Finished processing /home/ubuntu/JAI/data/sampled_GU_content_2022.csv\n",
      "INFO:root:------------------------\n",
      "INFO:root:------------------------\n",
      "INFO:root:Reading /home/ubuntu/JAI/data/sampled_GU_content_2021.csv data\n",
      "INFO:root:Extracting named entities from /home/ubuntu/JAI/data/sampled_GU_content_2021.csv article 0\n",
      "INFO:root:Finished processing /home/ubuntu/JAI/data/sampled_GU_content_2021.csv\n",
      "INFO:root:------------------------\n",
      "INFO:root:------------------------\n",
      "INFO:root:Reading /home/ubuntu/JAI/data/sampled_GU_content_2020.csv data\n",
      "INFO:root:Extracting named entities from /home/ubuntu/JAI/data/sampled_GU_content_2020.csv article 0\n",
      "INFO:root:Finished processing /home/ubuntu/JAI/data/sampled_GU_content_2020.csv\n",
      "INFO:root:------------------------\n",
      "INFO:root:------------------------\n",
      "INFO:root:Reading /home/ubuntu/JAI/data/sampled_GU_content_2019.csv data\n",
      "INFO:root:Extracting named entities from /home/ubuntu/JAI/data/sampled_GU_content_2019.csv article 0\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7554 > 512). Running this sequence through the model will result in indexing errors\n",
      "INFO:root:Finished processing /home/ubuntu/JAI/data/sampled_GU_content_2019.csv\n",
      "INFO:root:------------------------\n",
      "INFO:root:------------------------\n",
      "INFO:root:Reading /home/ubuntu/JAI/data/sampled_GU_content_2018.csv data\n",
      "INFO:root:Extracting named entities from /home/ubuntu/JAI/data/sampled_GU_content_2018.csv article 0\n",
      "INFO:root:Finished processing /home/ubuntu/JAI/data/sampled_GU_content_2018.csv\n",
      "INFO:root:------------------------\n",
      "INFO:root:------------------------\n",
      "INFO:root:Reading /home/ubuntu/JAI/data/sampled_GU_content_2017.csv data\n",
      "INFO:root:Extracting named entities from /home/ubuntu/JAI/data/sampled_GU_content_2017.csv article 0\n",
      "INFO:root:Finished processing /home/ubuntu/JAI/data/sampled_GU_content_2017.csv\n",
      "INFO:root:------------------------\n",
      "INFO:root:------------------------\n",
      "INFO:root:Reading /home/ubuntu/JAI/data/sampled_GU_content_2016.csv data\n",
      "INFO:root:Extracting named entities from /home/ubuntu/JAI/data/sampled_GU_content_2016.csv article 0\n",
      "INFO:root:Finished processing /home/ubuntu/JAI/data/sampled_GU_content_2016.csv\n",
      "INFO:root:------------------------\n",
      "INFO:root:------------------------\n",
      "INFO:root:Reading /home/ubuntu/JAI/data/sampled_GU_content_2015.csv data\n",
      "INFO:root:Extracting named entities from /home/ubuntu/JAI/data/sampled_GU_content_2015.csv article 0\n",
      "INFO:root:Finished processing /home/ubuntu/JAI/data/sampled_GU_content_2015.csv\n",
      "INFO:root:------------------------\n",
      "INFO:root:------------------------\n",
      "INFO:root:Reading /home/ubuntu/JAI/data/sampled_GU_content_2014.csv data\n",
      "INFO:root:Extracting named entities from /home/ubuntu/JAI/data/sampled_GU_content_2014.csv article 0\n",
      "INFO:root:Finished processing /home/ubuntu/JAI/data/sampled_GU_content_2014.csv\n",
      "INFO:root:------------------------\n",
      "INFO:root:------------------------\n",
      "INFO:root:Reading /home/ubuntu/JAI/data/sampled_GU_content_2013.csv data\n",
      "INFO:root:Extracting named entities from /home/ubuntu/JAI/data/sampled_GU_content_2013.csv article 0\n",
      "INFO:root:Finished processing /home/ubuntu/JAI/data/sampled_GU_content_2013.csv\n",
      "INFO:root:------------------------\n",
      "INFO:root:------------------------\n",
      "INFO:root:Reading /home/ubuntu/JAI/data/sampled_GU_content_2012.csv data\n",
      "INFO:root:Extracting named entities from /home/ubuntu/JAI/data/sampled_GU_content_2012.csv article 0\n",
      "INFO:root:Finished processing /home/ubuntu/JAI/data/sampled_GU_content_2012.csv\n",
      "INFO:root:------------------------\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import logging\n",
    "import pandas as pd\n",
    "import spacy\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "spacy.prefer_gpu()\n",
    "\n",
    "def get_data(doc_index,doc,ent_types):\n",
    "    \"\"\"\n",
    "    Extract the entity data (text, label, start, end, start_char, end_char) \n",
    "    from a Spacy Doc and format into JSON.\n",
    "    Filter output to only include `ent_types`.\n",
    "    :returns dict\n",
    "    \"\"\"\n",
    "    ents = [\n",
    "        {\n",
    "            \"text\": ent.text,\n",
    "            \"label\": ent.label_,\n",
    "            \"start\": ent.start,\n",
    "            \"end\": ent.end,\n",
    "            \"start_char\": ent.start_char,\n",
    "            \"end_char\": ent.end_char,\n",
    "        }\n",
    "        for ent in doc.ents\n",
    "        if ent.label_ in ent_types\n",
    "    ]\n",
    "    return {\"doc_index\":doc_index,\n",
    "            #\"text\": doc.text, \n",
    "            \"ents\": ents}\n",
    "\n",
    "logging.info('Starting NER extraction')\n",
    "\n",
    "logging.info('Loading Spacy model')\n",
    "NER_TRF_MODEL=\"en_core_web_trf\"\n",
    "nlp = spacy.load(NER_TRF_MODEL)\n",
    "ent_types = nlp.pipe_labels[\"ner\"]\n",
    "unwanted_ent_types=['CARDINAL','LANGUAGE','ORDINAL','PERCENT','QUANTITY','TIME']\n",
    "ent_types = [ent for ent in ent_types if ent not in unwanted_ent_types]\n",
    "csv_file_list=glob.glob('/home/ubuntu/JAI/data/*.csv')\n",
    "csv_file_list.sort()\n",
    "#start on most recent year\n",
    "csv_file_list.reverse()\n",
    "\n",
    "logging.info('Starting iteration through csv files')\n",
    "for csv_file in csv_file_list:\n",
    "    csv_file_name=''.join(csv_file.split('/')[-1].split('.')[-2])\n",
    "    export_csv_file=f'/home/ubuntu/JAI/data/extracted_named_entities_output/{csv_file_name}_ner.csv.gz'\n",
    "    if glob.glob(export_csv_file):\n",
    "        # Stop entity extraction for files already processed\n",
    "        continue\n",
    "    logging.info('------------------------')\n",
    "    logging.info(f'Reading {csv_file} data')\n",
    "    try:\n",
    "        data=pd.read_csv(csv_file)\n",
    "    except:\n",
    "        continue\n",
    "    data=data.iloc[:1000]\n",
    "    data['body_text']=data['body_text'].astype('str')\n",
    "    # Ensure incremental ordered index to reference back to articles in the dataset\n",
    "    data=data.reset_index(drop=True).sort_index()\n",
    "    data=data.to_dict('index')\n",
    "    gu_article_list=[data[key]['body_text'] for key in data.keys()]\n",
    "    response_body = []\n",
    "    exceptions=[]\n",
    "    for doc_index,doc in enumerate(nlp.pipe(gu_article_list, batch_size=20)):\n",
    "        if doc_index%1000==0:\n",
    "            logging.info(f'Extracting named entities from {csv_file} article {doc_index}')\n",
    "        response_body.append(get_data(doc_index,doc, ent_types))\n",
    "    d={}\n",
    "    i=-1\n",
    "    for response in response_body:\n",
    "        for ent_ind,ent in enumerate(response['ents']):\n",
    "            i+=1\n",
    "            ent['doc_index']=response['doc_index']\n",
    "            d[i]=ent\n",
    "    df=pd.DataFrame.from_dict(d,orient='index')\n",
    "    df.to_csv(export_csv_file)\n",
    "    logging.info(f'Finished processing {csv_file}')\n",
    "    logging.info('------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b5d87-2970-4329-97e6-56f717aca0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
