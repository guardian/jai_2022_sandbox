{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ebaab0b-e214-4aab-ab03-f9be450b9727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27950430-b6f4-4d44-b10e-e7fe161e5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_article_paragraphs(html_text: str):\n",
    "    \n",
    "    \"\"\" Takes the full html of an article (CAPI format) and strips out all HTML tags. \n",
    "        Creates paragraphs from the <p></p> HTML items.\n",
    "\n",
    "        :param text: the raw HTML of an article\n",
    "        \n",
    "        returns: article paragraphs: list(str)\n",
    "        \"\"\"\n",
    "\n",
    "    soup = BeautifulSoup(html_text, features=\"html.parser\")\n",
    "    \n",
    "    # Remove article embellishments (sub-headings, figures, asides, etc.) \n",
    "    for h2 in soup.find_all('h2'):\n",
    "        try:\n",
    "            soup.h2.extract()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for span in soup.find_all('span'):\n",
    "        try:            \n",
    "            soup.span.extract()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for aside in soup.find_all('aside'):\n",
    "        try:\n",
    "            soup.aside.extract()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    for figure in soup.find_all('figure'):\n",
    "        try:\n",
    "            soup.figure.extract()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    for a in soup.find_all('a'):\n",
    "        a.unwrap()\n",
    "        \n",
    "    paragraphs = [p.getText() for p in  soup.find_all('p')]\n",
    "    \n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c72623d-00dd-4fb8-9508-102da06c6085",
   "metadata": {},
   "outputs": [],
   "source": [
    "gu_sample=pd.read_csv('gu_resampled_by_section_id.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87963613-d2c1-4f53-bf9a-8dd957f9ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gu_sample['paragraphs'] = gu_sample['body_html'].apply(get_article_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80587380-c8a3-4624-a52b-6b21d2e35719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb4b36a-350a-424f-92e9-3e1c55e79ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
